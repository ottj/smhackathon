{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple, Counter\n",
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset_path, lyric_len):\n",
    "    labels = []\n",
    "    data = []\n",
    "    tags = ['<START>', '<END>', '<B>' <'UKN>', '<PAD>'] \n",
    "    \n",
    "    with open(dataset_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        count = 0\n",
    "        new_song = 1\n",
    "        for row in reader:\n",
    "            if count > 0:\n",
    "                label = ['<START>'] \n",
    "                for word in row[1].split(' '):\n",
    "                    label += [word]\n",
    "                if len(label) >= hps_dict['title_dec_steps']:\n",
    "                    label = label[:hps_dict['title_dec_steps']-1]\n",
    "                label += ['<END>']\n",
    "                while len(label) < hps_dict['title_dec_steps']:\n",
    "                    label += ['<PAD>']\n",
    "                labels += [label]\n",
    "                current_lyric = ['<START>']\n",
    "                for line in row[2].split('\\n'):\n",
    "                    for word in line.split(' '):\n",
    "                        if word is not \"\":\n",
    "                            current_lyric += [word]\n",
    "                    current_lyric += ['<B>']\n",
    "                if len(current_lyric) >= lyric_len:\n",
    "                    current_lyric = current_lyric[:lyric_len-1]\n",
    "                current_lyric += ['<END>']\n",
    "                while len(current_lyric) < lyric_len:\n",
    "                    current_lyric += ['<PAD>']\n",
    "                data += [current_lyric]\n",
    "            count += 1    \n",
    "    return labels,data\n",
    "\n",
    "\n",
    "def words_frequency(words_1d):\n",
    "    vocabulary_size=20000\n",
    "    count=[['<UNK>',-1]]\n",
    "\n",
    "    counter = Counter(words_1d).most_common(vocabulary_size - 1)\n",
    "    count.extend(counter)\n",
    "    dictionary={}\n",
    "    for word,_ in count:\n",
    "        dictionary[word]=len(dictionary)\n",
    "\n",
    "    data=[]\n",
    "    unk_count=0\n",
    "    for word in words_1d:\n",
    "        if word in dictionary:\n",
    "            index=dictionary[word]\n",
    "        else:\n",
    "            index=0\n",
    "            unk_count+=1\n",
    "        data.append(index)\n",
    "    count[0] = ('<UNK>', unk_count)\n",
    "    reverse_dictionary=dict(zip(dictionary.values(),dictionary.keys()))\n",
    "    return data,count,dictionary,reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleGenerator(object):\n",
    "    \"\"\"\n",
    "        generating the title based on the lyrics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hps, vocab):\n",
    "        self._vocab = vocab\n",
    "        self._hps = hps\n",
    "        \n",
    "    def _add_placeholders(self):\n",
    "        \n",
    "        hps = self._hps\n",
    "        self._lyrics_batch = tf.placeholder(tf.int32,\n",
    "                                            [hps.batch_size, hps.lyrics_enc_steps],\n",
    "                                            name='lyrics_batch')\n",
    "        self._titles_batch = tf.placeholder(tf.int32,\n",
    "                                            [hps.batch_size, hps.title_dec_steps],\n",
    "                                            name='titles_batch')\n",
    "        \n",
    "        self._titles_mask = tf.placeholder(tf.float32,\n",
    "                                            [hps.batch_size, hps.title_dec_steps],\n",
    "                                            name='titles_mask')\n",
    "    \n",
    "    def _make_feed_dict(self, batch):\n",
    "        \n",
    "        feed_dict = {}\n",
    "        \n",
    "        feed_dict[self._lyrics_batch] = batch.lyrics\n",
    "        feed_dict[self._titles_batch] = batch.titles\n",
    "        feed_dict[self._titles_mask] = batch.titles_mask\n",
    "        \n",
    "        return feed_dict\n",
    "    \n",
    "    def _add_encoder(self, encoder_inputs):\n",
    "        \n",
    "        hps = self._hps\n",
    "        \n",
    "        with tf.variable_scope('encoder') as encoder:\n",
    "            if hps.cell_type == 'lstm':\n",
    "                cell = tf.nn.rnn_cell.LSTMCell(\n",
    "                    hps.hidden_dim,\n",
    "                    initializer=self._rand_unif_init,\n",
    "                    state_is_tuple=True)\n",
    "            elif hps.cell_type == 'gru':\n",
    "                cell = tf.nn.rnn_cell.GRUCell(\n",
    "                    hps.hidden_dim,\n",
    "                    kernel_initializer=self._rand_unif_init)\n",
    "            else:\n",
    "                raise ValueError(\"cell_type is not assigned\")\n",
    "            outputs, state = tf.nn.dynamic_rnn(cell, encoder_inputs,\n",
    "                                               swap_memory=True,\n",
    "                                               dtype=tf.float32,\n",
    "                                               )\n",
    "            encoder_outputs = tf.concat(axis=2, values=outputs)\n",
    "            \n",
    "        return encoder_outputs, state\n",
    "    \n",
    "    def _add_decoder(self, decoder_inputs, enc_state):\n",
    "        \n",
    "        hps = self._hps\n",
    "        \n",
    "        with tf.variable_scope('decoder'):\n",
    "            if hps.cell_type == 'lstm':\n",
    "                cell = tf.nn.rnn_cell.LSTMCell(\n",
    "                    hps.hidden_dim,\n",
    "                    state_is_tuple=True,\n",
    "                    nitializer=self._rand_unif_init)\n",
    "            elif hps.cell_type == 'gru':\n",
    "                cell = tf.nn.rnn_cell.GRUCell(\n",
    "                    hps.hidden_dim,\n",
    "                    kernel_initializer=self._rand_unif_init)\n",
    "            else:\n",
    "                raise ValueError(\"cell_type is not assigned\")\n",
    "\n",
    "            outputs, state = tf.nn.dynamic_rnn(cell, decoder_inputs,\n",
    "                                               dtype=tf.float32,\n",
    "                                               initial_state=enc_state)\n",
    "            \n",
    "        return outputs, state\n",
    "    \n",
    "    def _add_seq2seq(self):\n",
    "        \n",
    "        hps = self._hps\n",
    "        \n",
    "        vsize = len(self._vocab)\n",
    "        \n",
    "        with tf.variable_scope('seq2seq'):\n",
    "            \n",
    "            self._rand_unif_init = tf.random_uniform_initializer(\n",
    "                -hps.rand_unif_init_mag, hps.rand_unif_init_mag, seed=123)\n",
    "            self._trunc_norm_init = tf.truncated_normal_initializer(\n",
    "                stddev=hps.trunc_norm_init_std)\n",
    "            \n",
    "            with tf.variable_scope('embedding'):\n",
    "                embedding = tf.get_variable(\n",
    "                    'embedding',\n",
    "                    [vsize, hps.emb_dim],\n",
    "                    dtype = tf.float32,\n",
    "                    initializer=self._trunc_norm_init)\n",
    "#                 if hps.mode == 'train':\n",
    "#                     self._add_emb_vis(embedding)\n",
    "                lyrics_emb = tf.nn.embedding_lookup(embedding,\n",
    "                                                   self._lyrics_batch)\n",
    "                titles_emb = tf.nn.embedding_lookup(embedding,\n",
    "                                                   self._titles_batch)\n",
    "            _, enc_state = self._add_encoder(lyrics_emb)\n",
    "            dec_outputs, _ = self._add_decoder(titles_emb,\n",
    "                                               enc_state)\n",
    "            \n",
    "            with tf.variable_scope('output_projection') as projection:\n",
    "                \n",
    "                titles_vocab_scores = []\n",
    "                \n",
    "                w = tf.get_variable('w', [hps.hidden_dim, vsize],\n",
    "                                    dtype=tf.float32,\n",
    "                                    initializer=self._trunc_norm_init)\n",
    "                v = tf.get_variable('v', [vsize], dtype=tf.float32,\n",
    "                                    initializer=self._trunc_norm_init)\n",
    "                title_vocab_scores = []\n",
    "                dec_outputs_list = tf.unstack(dec_outputs, axis=1)\n",
    "                for i, output in enumerate(dec_outputs_list):\n",
    "                    if i > 0:\n",
    "                        tf.get_variable_scope().reuse_variables()\n",
    "                    titles_vocab_scores.append(tf.nn.xw_plus_b(output, w, v))\n",
    "            titles_vocab_scores_stack = tf.stack(titles_vocab_scores, axis=1)\n",
    "            self.titles_dec_ids = tf.argmax(titles_vocab_scores_stack, axis = -1)\n",
    "            print(titles_vocab_scores_stack.get_shape())\n",
    "            print(self._titles_batch.get_shape())\n",
    "            self._loss = tf.contrib.seq2seq.sequence_loss(titles_vocab_scores_stack,\n",
    "                                                         self._titles_batch,\n",
    "                                                         self._titles_mask)\n",
    "            print(self._loss)\n",
    "            tf.summary.scalar('loss', self._loss)\n",
    "    def _add_train_op(self):\n",
    "        loss_to_minimize = self._loss\n",
    "        tvars = tf.trainable_variables()\n",
    "        gradients = tf.gradients(\n",
    "            loss_to_minimize,\n",
    "            tvars,\n",
    "            aggregation_method=tf.AggregationMethod.EXPERIMENTAL_TREE)\n",
    "        \n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            #TODO: add into hps\n",
    "            grads, global_norm = tf.clip_by_global_norm(\n",
    "                gradients, self._hps.max_grad_norm)\n",
    "        tf.summary.scalar('global_norm', global_norm)\n",
    "        #TODO: add into hps\n",
    "        optimizer = tf.train.AdamOptimizer(self._hps.lr)\n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            self._train_op = optimizer.apply_gradients(\n",
    "                zip(grads, tvars),\n",
    "                global_step=self.global_step, name='train_step')\n",
    "            \n",
    "    def build_graph(self):\n",
    "        tf.logging.info('Building graph...')\n",
    "        t0 = time.time()\n",
    "        self._add_placeholders()\n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            self._add_seq2seq()\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        if self._hps.mode == 'train':\n",
    "            self._add_train_op()\n",
    "        self._summaries = tf.summary.merge_all()\n",
    "        t1 = time.time()\n",
    "        tf.logging.info(\"Time to build graph: %i seconds\", t1 - t0)\n",
    "        \n",
    "    def run_train_step(self, sess, batch):\n",
    "    \n",
    "        feed_dict = self._make_feed_dict(batch)\n",
    "        \n",
    "        to_return = {\n",
    "            'train_op' : self._train_op,\n",
    "            'summaries' : self._summaries,\n",
    "            'loss' : self._loss,\n",
    "            'global_step' : self.global_step,\n",
    "            'title_ids': self.titles_dec_ids\n",
    "        }\n",
    "        \n",
    "        return sess.run(to_return, feed_dict)\n",
    "    \n",
    "    def run_eval_step(self, sess, batch):\n",
    "\n",
    "        feed_dict = self._make_feed_dict(batch)\n",
    "        to_return = {\n",
    "            'summaries': self._summaries,\n",
    "            'loss': self._loss,\n",
    "            'global_step': self.global_step,\n",
    "            'title_ids': self.titles_dec_ids\n",
    "        }\n",
    "\n",
    "        return sess.run(to_return, feed_dict)\n",
    "    \n",
    "    def run_eval_step(self, sess, batch):\n",
    "\n",
    "        feed_dict = self._make_feed_dict(batch)\n",
    "        to_return = {\n",
    "            'summaries': self._summaries,\n",
    "            'loss': self._loss,\n",
    "            'title_ids': self.titles_dec_ids\n",
    "        }\n",
    "\n",
    "        return sess.run(to_return, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(object):\n",
    "    \n",
    "    def __init__(self, lyrics, lyrics_mask, titles, titles_mask):\n",
    "        self.lyrics = np.array(lyrics)\n",
    "        self.lyrics_mask = np.array(lyrics_mask)\n",
    "        self.titles = np.array(titles)\n",
    "        self.titles_mask = np.array(titles_mask)\n",
    "\n",
    "class Batcher(object):\n",
    "    \n",
    "    def __init__(self, hps, data):\n",
    "        self._hps = hps\n",
    "        self._data = data\n",
    "        \n",
    "    def next_batch(self):\n",
    "        \n",
    "        hps = self._hps\n",
    "        \n",
    "        data_size = len(self._data)\n",
    "        \n",
    "        batch_index = np.random.randint(data_size,\n",
    "                                        size=hps.batch_size)\n",
    "        \n",
    "        # TODO, depends on the data structure\n",
    "        titles = []\n",
    "        lyrics = []\n",
    "        titles_mask = []\n",
    "        lyrics_mask = []\n",
    "        for idx in batch_index:\n",
    "            titles.append(self._data[idx][0])\n",
    "            lyrics.append(self._data[idx][1])\n",
    "            titles_mask.append(self._data[idx][2])\n",
    "            lyrics_mask.append(self._data[idx][3])\n",
    "        \n",
    "        batch = Batch(lyrics, lyrics_mask, titles, titles_mask)\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, batcher, sess_context_manager,\n",
    "                 sv, summary_writer, vocab):\n",
    "    tf.logging.info(\"Starting run training\")\n",
    "    with sess_context_manager as sess:\n",
    "        while True:\n",
    "            batch = batcher.next_batch()\n",
    "            tf.logging.info('Running training step...')\n",
    "            t0 = time.time()\n",
    "            result = model.run_train_step(sess, batch)\n",
    "            t1 = time.time()\n",
    "            tf.logging.info('seconds for training step: %.3f', t1 - t0)\n",
    "\n",
    "            loss = result['loss']\n",
    "            tf.logging.info('loss: %f', loss)\n",
    "\n",
    "            title_ids = result['title_ids']\n",
    "            summaries = result['summaries']\n",
    "            train_step = result['global_step']\n",
    "        \n",
    "#         summary_writer.add_summary(summaries, train_step)\n",
    "#         if train_step % 100 == 0:\n",
    "#             summary_writer.flush()\n",
    "            \n",
    "def get_config():\n",
    "    \"\"\"Returns config for tf.session\"\"\"\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth=True\n",
    "    return config\n",
    "        \n",
    "def setup_training(model, batcher, vocab):\n",
    "    #TODO\n",
    "    model.build_graph()\n",
    "    saver = tf.train.Saver(max_to_keep=3)\n",
    "    sv = tf.train.Supervisor(logdir=hps.train_dir,\n",
    "                         is_chief=True,\n",
    "                         saver=saver,\n",
    "                         summary_op=None,\n",
    "                         save_summaries_secs=60,\n",
    "                         save_model_secs=60,\n",
    "                         global_step=model.global_step)\n",
    "    summary_writer = sv.summary_writer\n",
    "    tf.logging.info('Preparing or waiting for session...')\n",
    "    sess_context_manager = sv.prepare_or_wait_for_session(config=get_config())\n",
    "    tf.logging.info('Created session')\n",
    "    try:\n",
    "        run_training(model, batcher, sess_context_manager, sv, summary_writer, vocab)\n",
    "    except KeyboardInterrupt:\n",
    "        tf.logging.info('Caught keyboard interrupt or worker. ' + \\\n",
    "                        'Stopping supervisor')\n",
    "        sv.stop()\n",
    "        \n",
    "def run_decode(model, hps, batcher, vocab):\n",
    "    \"\"\"\n",
    "      Run the model with the best parameter, to evaluate the model and get ROUGE\n",
    "      BLEU scores.\n",
    "    \"\"\"\n",
    "\n",
    "    model.build_graph()\n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session(config=get_config())\n",
    "    ckpt = tf.train.get_checkpoint_state(hps.ckpt_file)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        ValueError(\"check point doesn't exist\")\n",
    "\n",
    "    file_path_dict = {}\n",
    "    hypo_dict = {}\n",
    "    ref_dict = {}\n",
    "\n",
    "    for _ in range(20):\n",
    "        batch = batcher.next_batch()\n",
    "        # if the next batch is None, then stop the evluation.\n",
    "        if not batch:\n",
    "            break\n",
    "        t0=time.time()\n",
    "        result = model.run_eval_step(sess, batch)\n",
    "#         lyrics = [reverse_vocab batch.lyrics[0]]\n",
    "        title_dec_ids = result['title_ids']\n",
    "        example = title_dec_ids[0]\n",
    "        sentences = [reverse_vocab[_] for _ in example]\n",
    "        print(sentences)\n",
    "        t1=time.time()\n",
    "        tf.logging.info('seconds for batch: %.2f', t1-t0)\n",
    "\n",
    "def main(data):\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    tf.logging.info('Starting seq2seq in %s mode...', (hps.mode))\n",
    "    batcher = Batcher(hps, data)\n",
    "    \n",
    "    tf.set_random_seed(111)\n",
    "    \n",
    "    #TODO: initialize the vocab\n",
    "    \n",
    "    if hps.mode == 'train':\n",
    "        print(\"Creating model for training...\")\n",
    "        model = TitleGenerator(hps, vocab)\n",
    "        setup_training(model, batcher, vocab)\n",
    "    elif hps.mode == 'test':\n",
    "        print(\"Creating model...\")\n",
    "        model = TitleGenerator(hps, vocab)\n",
    "        run_decode(model, hps, batcher, vocab)\n",
    "    else:\n",
    "        raise ValueError(\"Lack of 'mode' flag, must be one of train/eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset.csv'\n",
    "titles, lyrics = preprocess(data_path, hps.lyrics_enc_steps)\n",
    "\n",
    "all_words = []\n",
    "for t in titles:\n",
    "    [all_words.append(_) for _ in t]\n",
    "for l in lyrics:\n",
    "    [all_words.append(_) for _ in l]\n",
    "    \n",
    "_, count, vocab, reverse_vocab = words_frequency(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for t, l in zip(titles, lyrics):\n",
    "    t_num = [vocab[_] if _ in vocab.keys() else vocab['<UNK>'] for _ in t]\n",
    "    l_num = [vocab[_] if _ in vocab.keys() else vocab['<UNK>']for _ in l]\n",
    "    t_mask = [1 if _ is not '<PAD>' else 0 for _ in t]\n",
    "    l_mask = [1 if _ is not '<PAD>' else 0 for _ in l]\n",
    "    data.append([t_num, l_num, t_mask, l_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting seq2seq in test mode...\n",
      "Creating model...\n",
      "INFO:tensorflow:Building graph...\n",
      "(32, 10, 20000)\n",
      "(32, 10)\n",
      "Tensor(\"seq2seq/sequence_loss/truediv:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Time to build graph: 0 seconds\n",
      "INFO:tensorflow:Restoring parameters from ./model.ckpt-220\n",
      "['<START>', 'How', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.18\n",
      "['<START>', 'How', 'Trick', '<UNK>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.14\n",
      "['<START>', 'I', 'You', 'See', 'The', 'World', '<END>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.13\n",
      "['<START>', 'You', '<END>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.13\n",
      "['<START>', 'How', '<UNK>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.13\n",
      "['<START>', 'Blue', 'Trick', 'You', '<UNK>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.13\n",
      "['<START>', 'Blue', 'In', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.13\n",
      "['<START>', 'How', 'You', 'The', '<UNK>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', 'How', 'Is', 'The', 'Life', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', 'How', 'Knows', '<UNK>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.13\n",
      "['<START>', 'How', 'I', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', 'The', '<UNK>', 'Blues', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', 'Blue', 'Trick', 'Knows', '<UNK>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', 'I', 'You', 'Man', 'To', 'Love', '<END>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', '<UNK>', 'Man', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', 'Blue', '<UNK>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', 'Blue', 'The', '<UNK>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', 'Ruby', 'Out', 'The', '<END>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.13\n",
      "['<START>', 'Blue', 'In', '<END>', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n",
      "['<START>', 'Blue', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "INFO:tensorflow:seconds for batch: 0.12\n"
     ]
    }
   ],
   "source": [
    "hps_dict = {\n",
    "    'mode': 'test',\n",
    "    'batch_size': 32,\n",
    "    'hidden_dim': 512,\n",
    "    'emb_dim': 128,\n",
    "    'cell_type': 'gru',\n",
    "    'lyrics_enc_steps': 200,\n",
    "    'title_dec_steps': 10,\n",
    "    'rand_unif_init_mag': 0.1,\n",
    "    'trunc_norm_init_std': 0.01,\n",
    "    'max_grad_norm': 2,\n",
    "    'train_dir':'./',\n",
    "    'lr':0.001,\n",
    "    'ckpt_file': './'\n",
    "}\n",
    "\n",
    "hps = namedtuple(\"HParams\", hps_dict.keys())(**hps_dict)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "main(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_state = tf.train.get_checkpoint_state(hps.train_dir, latest_filename='checkpoint')\n",
    "ckpt_state.model_checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
